\section{Matrices}\label{matrices}

\subsection{Definiciones}\label{matrices-definiciones}

\[
	\begin{pmatrix}
		a_{11} & a_{12} & \cdots & a_{1n} \\
		a_{21} & a_{22} & \cdots & a_{2n} \\
		\vdots & \vdots & \ddots & \vdots \\
		a_{m1} & a_{m2} & \cdots & a_{mn}
	\end{pmatrix}
\]

Dado un cuerpo $K$ y los conjuntos $M = \{1,2,\ldots,m\}$ y $N = \{1,2,\ldots,n\}$, definimos una matriz como una aplicación $A : M \times N \rightarrow K$ de forma que cada elemento de la misma viene identificado unívocamente como $a_{ij} : 1 \leq i \leq m$ y $1 \leq j \leq m$.
Por ejemplo, ésta sería la matriz resultante de la aplicación $A : \{1,2\} \times \{1,2\} \rightarrow \mathbb{N}; A(1,1) = 1, A(1,2) = 9, A(2,1) = 7, A(2,2) = 0$:

\[
	\begin{pmatrix}
		1 & 9 \\
		7 & 0
	\end{pmatrix}
\]

Diremos que una matriz tiene $m$ filas y $n$ columnas y llamaremos fila $i$-ésima y columna $j$-ésima a los elementos de índice $i$ y $j$ respectivamente.
Diremos que una matriz es cuadrada si $m = n$.
Si una matriz es cuadrada, llamaremos \textbf{diagonal principal} a los elementos $a_{ij} : i = j$ y \textbf{diagonal secundaria} a los elementos $a_{ij} : i+j = n+1$.

\begin{figure}[h!]
\[
	\begin{pmatrix}
		\boldsymbol{a_{11}} & a_{12}                 & \cdots & a_{1,n-1}                 & \boldsymbol{a_{1n}} \\
		a_{21}              & \boldsymbol{a_{22}}    & \cdots & \boldsymbol{a_{2,n-1}}    & a_{2n}              \\
		\vdots              & \vdots                 & \ddots & \vdots                    & \vdots              \\
		a_{m-1,1}           & \boldsymbol{a_{m-1,2}} & \cdots & \boldsymbol{a_{m-1,,n-1}} & a_{m-1,n}           \\
		\boldsymbol{a_{m1}} & a_{m2}                 & \cdots & a_{m,n-1}                 & \boldsymbol{a_{mn}}
	\end{pmatrix}
\]
\caption{Elementos de la diagonal principal y secundaria de una matriz}
\end{figure}

Si una matriz es cuadrada, puede ser de cuatro formas (entre otras):

\begin{itemize}
	\item\textbf{Triangular superior:}
		Si todos los elementos \textit{debajo} de la diagonal principal son nulos.
	\item\textbf{Triangular inferior}
		Si todos los elementos \textit{encima} de la diagonal principal son nulos.
	\item\textbf{Diagonal:}
		Si es triangular superior e inferior, es decir, sólo contiene elementos no nulos en la diagonal principal.
	\item\textbf{Escalar:}
		Si es diagonal y todos los elementos no nulos son iguales.
	\item\textbf{Identidad}
		Si es escalar y el elemento repetido es el 1.
		La llamaremos $Id_n$ para $n$ filas y columnas.
\end{itemize}

\begin{figure}[h!]
\[
	\begin{array}{ccccc}
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			0 & 0 & 2
		\end{pmatrix}

		&

		\begin{pmatrix}
			0 & 0 & 2 \\
			0 & 7 & 3 \\
			4 & 1 & 8
		\end{pmatrix}

		&

		\begin{pmatrix}
			6 & 0 & 0 \\
			0 & 2 & 0 \\
			0 & 0 & 5
		\end{pmatrix}

		&

		\begin{pmatrix}
			5 & 0 & 0 \\
			0 & 5 & 0 \\
			0 & 0 & 5
		\end{pmatrix}

		&

		\begin{pmatrix}
			1 & 0 & 0 \\
			0 & 1 & 0 \\
			0 & 0 & 1
		\end{pmatrix}
	\end{array}
\]
\caption{Matrices triangular superior, inferior, diagonal, escalar e identidad}
\end{figure}

Decimos que una fila o una columna es nula si todos sus elementos son 0.
Análogamente, decimos que una matriz es nula y la llamamos matriz $O$ si todas sus filas (o columnas) lo son.

\subsection{Transformaciones elementales, forma normal de Hermite}\label{transformaciones-elementales-forma-normal-de-hermite}

\subsubsection{Pivotes}

Antes de abordar las transformaciones elementales vamos a introducir el concepto de pivote.
En una fila o columna no nula, decimos que un elemento es el pivote de dicha fila si es el primer elemento no nulo de la misma.

\begin{figure}[h!]
\[
	\begin{array}{cc}
		\begin{pmatrix}
			\boldsymbol{1} & 3              & 0              & 0              \\
			0              & \boldsymbol{5} & 1              & 4              \\
			0              & 0              & 0              & \boldsymbol{2} \\
			0              & 0              & 0              & 7
		\end{pmatrix}

		&

		\begin{pmatrix}
			\boldsymbol{1} & \boldsymbol{3} & 0              & 0              \\
			0              & 5              & \boldsymbol{1} & \boldsymbol{4} \\
			0              & 0              & 0              & 2              \\
			0              & 0              & 0              & 7
		\end{pmatrix}
	\end{array}
\]
\caption{Matrices con los pivotes de fila (derecha) y de columna (izquierda) en negrita}
\end{figure}

Diremos que una matriz es escalonada por filas si cumple las siguientes condiciones:

\begin{itemize}
	\item
		Cualquier fila debajo de una fila nula también lo es.
		Es decir, todas las filas nulas están al final.
	\item
		Cada pivote está a la derecha del pivote de la fila anterior.
		El de la primera puede estar en cualquier posición siempre que el resto la respeten.
	\item
		Cada pivote vale 1.
\end{itemize}

Análogamente, decimos que una matriz es escalonada por clumna si cumple las siguientes condiciones:

\begin{itemize}
	\item
		Cualquier columna a la derecha de una columna nula también lo es.
		Es decir, todas las columnas nulas están al final.
	\item
		Cada pivote está debajo del pivote de la fila anterior.
		El de la primera puede estar en cualquier posición siempre que el resto la respeten.
	\item
		Cada pivote vale 1.
\end{itemize}

Diremos que una matriz es escalonada reducida por filas si en las columnas donde hay un pivote de fila el resto de elementos son nulos.
Análogamente, diremos que una matriz es escalonada reducida por columnas si en las filas donde hay un pivote de fila el resto de elementos son nulos.

\begin{figure}[h!]
\[
	\begin{array}{cccc}
		\begin{pmatrix}
			1 & 3 & 3 & 0 & 4 \\
			0 & 5 & 1 & 4 & 2 \\
			0 & 0 & 0 & 2 & 1 \\
			0 & 0 & 0 & 0 & 0 \\
			0 & 0 & 0 & 0 & 0
		\end{pmatrix}

		&

		\begin{pmatrix}
			1 & 0 & 3 & 0 & 4 \\
			0 & 5 & 1 & 0 & 2 \\
			0 & 0 & 0 & 2 & 1 \\
			0 & 0 & 0 & 0 & 0 \\
			0 & 0 & 0 & 0 & 0
		\end{pmatrix}

		&

		\begin{pmatrix}
			1 & 0 & 0 & 0 & 0 \\
			1 & 5 & 0 & 0 & 0 \\
			2 & 1 & 2 & 0 & 0 \\
			6 & 4 & 7 & 0 & 0 \\
			0 & 9 & 4 & 0 & 0
		\end{pmatrix}

		&

		\begin{pmatrix}
			1 & 0 & 0 & 0 & 0 \\
			0 & 5 & 0 & 0 & 0 \\
			0 & 0 & 2 & 0 & 0 \\
			6 & 4 & 7 & 0 & 0 \\
			0 & 9 & 4 & 0 & 0
		\end{pmatrix}
	\end{array}
\]
\caption{Matrices escalonada y escalonada reducida por filas y escalonada y escalonada reducida por columnas}
\end{figure}

\subsubsection{Transformaciones elementales}

Para transformar una matriz cualquiera en otra de forma escalonada reducida de forma que no perdamos la información contenida en las mismas vamos a definir tres formas de transformarla llamadas transformaciones elementales:

\begin{itemize}
	\item\textbf{Intercambiar dos filas \textit{a} y \textit{b} entre sí:}
		$E_{ab}$.
	\item\textbf{Multiplicar una fila \textit{a} por un escalar \textit{n}:}
		$E_{a}(n)$.
	\item\textbf{Sumarle una fila \textit{a} a una fila \textit{b} tras multiplicar esta última por un escalar \textit{n}:}
		$E_{ab}(n)$.
\end{itemize}

Análogamente podemos definimos las transformaciones elementales por columnas.

\begin{figure}[h!]
\[
	\begin{array}{ccc}
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{13}}
		\begin{pmatrix}
			3 & 0 & 2 \\
			0 & 7 & 3 \\
			4 & 1 & 8
		\end{pmatrix}

		&&

		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{13}}
		\begin{pmatrix}
			8 & 1 & 4 \\
			3 & 7 & 0 \\
			2 & 0 & 3
		\end{pmatrix}

		\\&&\\

		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{2}(5)}
		\begin{pmatrix}
			4 & 1  & 8  \\
			0 & 35 & 15 \\
			3 & 0  & 2
		\end{pmatrix}

		&&

		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{2}(5)}
		\begin{pmatrix}
			4 & 5  & 8 \\
			0 & 35 & 3 \\
			3 & 0  & 2
		\end{pmatrix}

		\\&&\\

		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{12}(3)}
		\begin{pmatrix}
			4 & 22 & 17 \\
			0 & 7  & 3  \\
			3 & 0  & 2
		\end{pmatrix}

		&&

		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\xrightarrow{E_{12}(3)}
		\begin{pmatrix}
			7  & 1 & 8 \\
			21 & 7 & 3 \\
			3  & 0 & 2
		\end{pmatrix}

		\\
	\end{array}
\]
\caption{Las tres transformaciones elementales por filas (izquierdas) y columnas (derecha)}
\end{figure}

Estas transformaciones son legales porque siempre podemos volver al estado previo de una transformación aplicando otra.
Esto significa que las transformaciones elementales pueden invertirse y, además, se tiene que la inversa de toda transformación elemental es otra transformación elemental del mismo tipo.
De esta forma, $E_{ab}^{-1} = E_{ba}$, ${E_a(n)}^{-1} = E_a(n^{-1})$ y ${E_{ab}(n)}^{-1} = E_{ab}(-n)$.

Decimos que una matriz $A$ es equivalente por filas a otra matriz $B$ y lo expresamos formalmente como $A \sim_f B$ si es posible pasar de $A$ a $B$ mediante transformaciones elementales por filas.
Esta relación es reflexiva ($A \sim_f A$), simétrica ($A \sim_f B \Rightarrow B \sim_f A$) y transitiva ($A \sim_f B \land B \sim_f C \Rightarrow A \sim_f C$).
Definimos análogamente las matrices equivalentes por columnas $A \sim_c B$.

\subsubsection{Matrices elementales}

A partir de una matriz identidad $A$ de tamaño $n \times n$ podemos definir una matriz elemental aplicando sobre ella una única operación elemental de cualquier tipo.
Llamaremos a esta nueva matriz de la misma forma que llamaríamos a la transformación elemental.

\begin{figure}[h!]
\[
	\begin{array}{ccc}
	E_{23} =
	\begin{pmatrix}
		1 & 0 & 0 & 0 \\
		0 & 0 & 1 & 0 \\
		0 & 1 & 0 & 0 \\
		0 & 0 & 0 & 1
	\end{pmatrix}

	&

	E_{2}(3) =
	\begin{pmatrix}
		1 & 0 & 0 & 0 \\
		0 & 3 & 0 & 0 \\
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1
	\end{pmatrix}

	&

	E_{21}(5) =
	\begin{pmatrix}
		1 & 5 & 0 & 0 \\
		0 & 1 & 0 & 0 \\
		0 & 0 & 1 & 0 \\
		0 & 0 & 0 & 1
	\end{pmatrix}

	\end{array}
\]
\caption{Matrices elementales $4 \times 4$ obtenidas con los tres tipos de trnasformaciones.}
\end{figure}

\subsubsection{Forma normal de Hermite}

\[\exists B \in M_{m \times n}(K) : B \text{ es escalonada reducida por filas}, B \sim_f A, \forall A \in M_{m \times n}(K)\]

Para encontrar esta matriz $B$ a partir de la primera iremos transfrmando cada una de sus columnas de izquierda a derecha en su forma escalonada reducida, de forma que iremos aprovechando el trabajo hecho con las transformaciones elementales para las columnas siguientes.
Veamos un ejemplo:

\[
	A =
	\begin{pmatrix}
		4 & 1 & 3 & 2 \\
		3 & 0 & 1 & 0 \\
		2 & 3 & 1 & 4
	\end{pmatrix}
	\in M_{3 \times 4}(\mathbb{Z}_5)
\]

Nos fijamos en que la matriz es de coeficientes en $\mathbb{Z}_5$.
Vamos a transformar la primera columna en una matriz escalonada reducida por filas aplicando transformaciones elementales:

\[
	\begin{pmatrix}
		4 \\
		3 \\
		2
	\end{pmatrix}
	\xrightarrow{E_{31}(1)}
	\begin{pmatrix}
		1 \\
		3 \\
		2
	\end{pmatrix}
	\xrightarrow{E_{32}(1)}
	\begin{pmatrix}
		1 \\
		0 \\
		2
	\end{pmatrix}
	\xrightarrow{E_{13}(3)}
	\begin{pmatrix}
		1 \\
		0 \\
		0
	\end{pmatrix}
\]

Estas transformaciones no se realizan de forma aislada, sino que se aplican a toda la matriz, de forma que también se transforman el resto de columnas:

\[
	\begin{pmatrix}
		4 & 1 & 3 & 2 \\
		3 & 0 & 1 & 0 \\
		2 & 3 & 1 & 4
	\end{pmatrix}
	\xrightarrow{E_{31}(1)}
	\begin{pmatrix}
		1 & 4 & 4 & 1 \\
		3 & 0 & 1 & 0 \\
		2 & 3 & 1 & 4
	\end{pmatrix}
	\xrightarrow{E_{32}(1)}
	\begin{pmatrix}
		1 & 4 & 4 & 1 \\
		0 & 3 & 2 & 4 \\
		2 & 3 & 1 & 4
	\end{pmatrix}
	\xrightarrow{E_{13}(3)}
	\begin{pmatrix}
		1 & 4 & 4 & 1 \\
		0 & 3 & 2 & 4 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
\]

Ahora queremos que el 3 de la segunda columna sea el pivote de la segunda fila, de forma que debemos buscar una serie de transformaciones que conviertan el 4 en un 0 y el 3 en un 1:

\[
	\begin{pmatrix}
		1 & 4 & 4 & 1 \\
		0 & 3 & 2 & 4 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
	\xrightarrow{E_{21}(2)}
	\begin{pmatrix}
		1 & 0 & 3 & 4 \\
		0 & 3 & 2 & 4 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
	\xrightarrow{E_{2}(2)}
	\begin{pmatrix}
		1 & 0 & 3 & 4 \\
		0 & 1 & 4 & 3 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
\]

Por último, vamos a transformar el último 3 de la tercera columna en pivote:

\[
	\begin{pmatrix}
		1 & 0 & 3 & 4 \\
		0 & 1 & 4 & 3 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
	\xrightarrow{E_{31}(4)}
	\begin{pmatrix}
		1 & 0 & 0 & 2 \\
		0 & 1 & 4 & 3 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
	\xrightarrow{E_{32}(2)}
	\begin{pmatrix}
		1 & 0 & 0 & 2 \\
		0 & 1 & 0 & 0 \\
		0 & 0 & 3 & 2
	\end{pmatrix}
	\xrightarrow{E_{3}(2)}
	\begin{pmatrix}
		1 & 0 & 0 & 2 \\
		0 & 1 & 0 & 0 \\
		0 & 0 & 1 & 4
	\end{pmatrix}
\]

Esta úlitma matriz escalonada reducida por filas a la que hemos llegado a partir de transformaciones elementales es lo que conocemos como la forma normal de Hermite por filas.
Esta serie de transformaciones no se hacen por capricho, sino porque tenemos que $A \sim_f B \Rightarrow A = B$, de forma que todas las operaciones que podríamos hacer con coeficientes colosalmente grandes podemos hacerlas con el mismo resultado usando coeficientes mucho más reducidos, ya que estas transformaciones nos aseguran que en esta nueva forma de la matriz habrá muchísimos más ceros que en la anterior.

\subsubsection{Rango de una matriz}

Llamamos rango de una matriz $A$ y los expresamos formalmente como $rg(A)$ al número de filas no nulas de su forma normal de Hermite por filas.

\subsection{Operaciones con matrices}\label{operaciones-con-matrices}

Para todas estas operaciones vamos a considerar que estamos trabajando con dos matrices $A$ y $B$ con la siguiente estructura:

\[
	\begin{array}{cc}
		A =
		\begin{pmatrix}
			a_{11} & a_{12} & \cdots & a_{1n} \\
			a_{21} & a_{22} & \cdots & a_{2n} \\
			\vdots & \vdots & \ddots & \vdots \\
			a_{m1} & a_{m2} & \cdots & a_{mn}
		\end{pmatrix}

		&

		B =
		\begin{pmatrix}
			b_{11} & b_{12} & \cdots & b_{1n} \\
			b_{21} & b_{22} & \cdots & b_{2n} \\
			\vdots & \vdots & \ddots & \vdots \\
			b_{m1} & b_{m2} & \cdots & b_{mn}
		\end{pmatrix}
	\end{array}
\]

\subsubsection{Las matrices se pueden sumar}

\[
	A+B =
	\begin{pmatrix}
		a_{11} + b_{11} & a_{12} + b_{12} & \cdots & a_{1n} + b_{1n} \\
		a_{21} + b_{21} & a_{22} + b_{22} & \cdots & a_{2n} + b_{2n} \\
		\vdots          & \vdots          & \ddots & \vdots          \\
		a_{m1} + b_{m1} & a_{m2} + b_{m2} & \cdots & a_{mn} + b_{mn}
	\end{pmatrix}
\]

La suma de matrices satisface las siguientes propiedades:

\begin{center}
\begin{tabular}{l l}
	\textbf{Propiedad}      & \textbf{Expresión}                                               \\
	\toprule
	Asociativa              & $(A+B) + C = A + (B+C), \forall A,B,C \in M_{m \times n}(K)$     \\
	Conmutativa             & $A+B = B+A, \forall A,B \in M_{m \times n}(K)$                   \\
	Elemento neutro (0)     & $A+O = A, \forall A \in M_{m \times n}(K)$                       \\
	Elemento opuesto ($-A$) & $A + (-A) = 0, \forall A \in M_{m \times n}(K)$                  \\
	Cancelativa             & $A+B = A+C \Rightarrow B=C, \forall A,B,C \in M_{m \times n}(K)$ \\
\end{tabular}
\end{center}

\subsubsection{Las matrices se pueden multiplicar por escalares}

\[
	A \cdot n =
	\begin{pmatrix}
		a_{11} \cdot n & a_{12} \cdot n & \cdots & a_{1n} \cdot n \\
		a_{21} \cdot n & a_{22} \cdot n & \cdots & a_{2n} \cdot n \\
		\vdots         & \vdots         & \ddots & \vdots         \\
		a_{m1} \cdot n & a_{m2} \cdot n & \cdots & a_{mn} \cdot n
	\end{pmatrix}
\]

El producto de matrices por escalares satisface las siguientes propiedades:

\begin{center}
\begin{tabular}{l l}
	\textbf{Propiedad}      & \textbf{Expresión}                                                                      \\
	\toprule
	Pseudosociativa         & $(n \cdot m) \cdot A = n \cdot (m \cdot A), \forall A \in M_{m \times n}(K), n,m \in K$ \\
	Conmutativa             & $n \cdot A = A \cdot n, \forall A \in M_{m \times n}(K), n \in K $                      \\
	Elemento neutro (1)     & $A \cdot 1 = A, \forall A \in M_{m \times n}(K)$                                        \\
	Cancelativa             & $A+B = A+C \Rightarrow B=C, \forall A,B,C \in M_{m \times n}(K)$                        \\
\end{tabular}
\end{center}

También tenemos que tanto la suma de escalares como de matrices es distributiva respecto al producto de ambos:

\[
	\begin{array}{c}
		n \cdot (A+B) = n \cdot A + n \cdot B, \forall A,B \in M_{m \times n}(K), n \in K \\
		(n+m) \cdot (A) = n \cdot A + m \cdot A, \forall A \in M_{m \times n}(K), n,m \in K
	\end{array}
\]

\subsubsection{Las matrices se pueden multiplicar entre sí}

Para multiplicar dos matrices $A$ y $B$ necesitaremos que la primera sea de tamaño $m \times n$ y la segunda, $n \times p$.
La matriz resultado $A \cdot B$ será de tamaño $m \times p$:

\[
	A \cdot B =
	\begin{pmatrix}
		a_{11}b_{11}+a_{12}b_{21}+\cdots+a_{1n}b_{n1} & a_{11}b_{12}+a_{12}b_{22}+\cdots+a_{1n}b_{n2} & \cdots & a_{11}b_{1p}+a_{12}b_{2p}+\cdots+a_{1n}b_{np} \\
		a_{21}b_{11}+a_{22}b_{21}+\cdots+a_{2n}b_{n1} & a_{21}b_{12}+a_{22}b_{22}+\cdots+a_{2n}b_{n2} & \cdots & a_{21}b_{1p}+a_{22}b_{2p}+\cdots+a_{2n}b_{np} \\
		\vdots                                        & \vdots                                        & \ddots & \vdots                                        \\
		a_{m1}b_{11}+a_{m2}b_{21}+\cdots+a_{mn}b_{n1} & a_{m1}b_{12}+a_{m2}b_{22}+\cdots+a_{mn}b_{n2} & \cdots & a_{m1}b_{1p}+a_{m2}b_{2p}+\cdots+a_{mn}b_{np}
	\end{pmatrix}
\]

Esta operación, que en principio parece un impenetrable, realmente es una generalización de la multiplicación de matrices de una fila y una columna.
Tengamos las siguientes matrices:

\[
	A =
	\begin{pmatrix}
		a_{11} & a_{12} & \cdots & a_{1n} \\
	\end{pmatrix}
	\ \ \ \ \ \ \ \ \ \ B =
	\begin{pmatrix}
		b_{11} \\
		b_{21} \\
		\vdots \\
		b_{n1}
	\end{pmatrix}
\]

Al ser matrices de tamaño $1 \times n$ y $n \times 1$, podemos multiplicarlas porque la primera tiene tantas filas como columnas la segunda y el tamaño de su resultado será una matriz de tamaño $1 \times 1$, que es lo mismo que un elemento de $K$.
Siguiendo el esquema anterior, calculamos el producto de ambas matrices como sigue:

\[
	A \cdot B =
	\begin{pmatrix}
		\sum_{i=1}^{n} a_{in}b_{nk}
	\end{pmatrix}
	=
	\begin{pmatrix}
		a_{11}b_{11}+a_{12}b_{21}+\cdots+a_{1n}b_{n1}
	\end{pmatrix}
\]

De esta forma, vamos a decir que $A$ es una \textit{matriz fila} y que $B$ es una \textit{matriz columna} y, notándolas como $F$ y $C$ respectivamente, vamos a reescribir la expresión anterior como el producto de filas y columnas de dos matrices:

\[
	A \cdot B =
	\begin{pmatrix}
		F_1 \cdot C_1 & F_1 \cdot C_2 & \cdots & F_1 \cdot C_p \\
		F_2 \cdot C_1 & F_2 \cdot C_2 & \cdots & F_2 \cdot C_p \\
		\vdots        & \vdots        & \ddots & \vdots        \\
		F_m \cdot C_1 & F_m \cdot C_2 & \cdots & F_m \cdot C_p
	\end{pmatrix}
\]

Por tanto, cada elemento de la multiplicación de dos matrices es el resultado de multiplicar la matriz resultante de fila de dicho elemento por la matriz resultante de su columna.

El producto de matrices entre sí satisface las siguientes propiedades:

\begin{center}
\begin{tabular}{l l}
	\textbf{Propiedad}       & \textbf{Expresión}                                                                          \\
	\toprule
	Asociativa con matrices  & $(A \cdot B)  \cdot  C = A  \cdot  (B \cdot C), \forall A,B,C \in M_{m \times n}(K)$        \\
	Asociativa con escalares & $(n \cdot A)  \cdot  B = n  \cdot  (A \cdot B), \forall A,B \in M_{m \times n}(K), n \in K$ \\
	Elemento neutro ($Id$)   & $A \cdot Id_n = Id_m \cdot A = A, \forall A \in M_{m \times n}(K)$                          \\
\end{tabular}
\end{center}

Una propiedad que estamos acostumbrados a ver y que aquí no aparece es que el producto de matrices entre sí no es conmutativo.
Vamos a utilizar esto a nuestro favor para usar el producto de matrices como herramienta para realizar y representar transformaciones elementales.

\subsubsection{Producto de matrices y matrices elementales}

Anteriormente vimos cómo las matrices elementales son matrices que se diferencian de la matriz identidad por una transformación elemental.
Estas matrices no existen por capricho matemático, sino que son las que nos permiten realizar transformaciones elementales sobre otras matrices mediante su producto.
Al multiplicar una matriz por una matriz elemental a la izquierda realizamos la transformación por filas, mientras que al hacerlo por la derecha transformamos por columnas.

\begin{figure}[h!]
\[
	\begin{array}{ccc}
		E_{13} \cdot A =
		\begin{pmatrix}
			0 & 0 & 1 \\
			0 & 1 & 0 \\
			1 & 0 & 0
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		=
		\begin{pmatrix}
			3 & 0 & 2 \\
			0 & 7 & 3 \\
			4 & 1 & 8
		\end{pmatrix}

		&&

		A \cdot E_{13} =
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			0 & 0 & 1 \\
			0 & 1 & 0 \\
			1 & 0 & 0
		\end{pmatrix}
		=
		\begin{pmatrix}
			8 & 1 & 4 \\
			3 & 7 & 0 \\
			2 & 0 & 3
		\end{pmatrix}

		\\&&\\

		E_{2}(5) \cdot A =
		\begin{pmatrix}
			1 & 0 & 0 \\
			0 & 5 & 0 \\
			0 & 0 & 1
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		=
		\begin{pmatrix}
			4 & 1  & 8  \\
			0 & 35 & 15 \\
			3 & 0  & 2
		\end{pmatrix}

		&&

		A \cdot E_{2}(5) =
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			1 & 0 & 0 \\
			0 & 5 & 0 \\
			0 & 0 & 1
		\end{pmatrix}
		=
		\begin{pmatrix}
			4 & 5  & 8 \\
			0 & 35 & 3 \\
			3 & 0  & 2
		\end{pmatrix}

		\\&&\\

		E_{12}(3) \cdot A =
		\begin{pmatrix}
			1 & 3 & 0 \\
			0 & 1 & 0 \\
			0 & 0 & 1
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		=
		\begin{pmatrix}
			4 & 22 & 17 \\
			0 & 7  & 3  \\
			3 & 0  & 2
		\end{pmatrix}

		&&

		A \cdot E_{12}(3) =
		\begin{pmatrix}
			4 & 1 & 8 \\
			0 & 7 & 3 \\
			3 & 0 & 2
		\end{pmatrix}
		\cdot
		\begin{pmatrix}
			1 & 3 & 0 \\
			0 & 1 & 0 \\
			0 & 0 & 1
		\end{pmatrix}
		=
		\begin{pmatrix}
			7  & 1 & 8 \\
			21 & 7 & 3 \\
			3  & 0 & 2
		\end{pmatrix}

		\\
	\end{array}
\]
\caption{Producto por matrices elementales por filas (izquierda) y columnas (derecha)}
\end{figure}

\[
	\begin{array}{c}
	A \sim_f B \Rightarrow \exists P : P \cdot A = B \\
	A \sim_c B \Rightarrow \exists P : A \cdot P = B
	\end{array}
\]

Por supuesto, podemos representar varias operaciones elementales encadenadas en una única matriz componiendo todas las operaciones que queramos a partir de la matriz identidad.
De esta forma, podemos encontrar una matriz de paso $P$ que nos sirva para transformar una matriz $A$ en otra matriz $B$ que sea equivalente por filas o columnas con ésta.
Por ejemplo, la matriz resultante de multiplicar la fila central por dos e intercambiar ésta con la primera se compone multiplicando las matrices elementales de cada una de éstas operaciones a la izquierda de las ya calculadas.

\[
	E_{12} \cdot E_{2}(2) =
	\begin{pmatrix}
		0 & 2 & 0 \\
		1 & 0 & 0 \\
		0 & 0 & 1
	\end{pmatrix}
\]

\subsection{Matriz traspuesta}\label{matriz-traspuesta}

\[
	A =
	\begin{pmatrix}
		a_{11} & a_{12} & \cdots & a_{1n} \\
		a_{21} & a_{22} & \cdots & a_{2n} \\
		\vdots & \vdots & \ddots & \vdots \\
		a_{m1} & a_{m2} & \cdots & a_{mn}
	\end{pmatrix}
	\Rightarrow A^t =
	\begin{pmatrix}
		a_{11} & a_{21} & \cdots & a_{m1} \\
		a_{12} & a_{22} & \cdots & a_{m2} \\
		\vdots & \vdots & \ddots & \vdots \\
		a_{1n} & a_{2n} & \cdots & a_{nm}
	\end{pmatrix}
\]

La traspuesta de una matriz (o matriz traspuesta) es la resultante de intercambiar sus filas y columnas.
Visualmente sería el equivalente a votearla 180$^\circ$ por los ejer $x$ e $y$.
Por ejemplo:

\[
	A =
	\begin{pmatrix}
		1 & 2 & 3 \\
		4 & 5 & 6
	\end{pmatrix}
	\Rightarrow A^t =
	\begin{pmatrix}
		1 & 4 \\
		2 & 5 \\
		3 & 6
	\end{pmatrix}
\]

La trasposición de matrices cumple las siguientes propiedades:

\begin{center}
\begin{tabular}{l l}
	\textbf{Propiedad}                & \textbf{Expresión}                                                      \\
	\toprule
	Traspoción de la suma             & ${(A+B)}^t = A^t + B^t , \forall A,B \in M_{m \times n}(K)$             \\
	Traspoción del producto escalar   & ${(n \cdot A)}^t = n \cdot A^t, \forall A \in M_{m \times n}(K), \in K$ \\
	Traspoción del producto matricial & ${(A \cdot B)}^t = B^t \cdot A^t, \forall A,B \in M_{m \times n}(K)$    \\
	Trasposición de la traspuesta     & ${(A^t)}^t = A, \forall A \in M_{m \times n}(K)$                        \\
\end{tabular}
\end{center}

\subsection{Matrices regulares}\label{matrices-regulares}

\[A \in M_n(K) \text{ es regular} \Rightarrow \exists B \in M_n(K) : A \cdot B = B \cdot A = Id_n\]

A esta matriz $B$ la llamamos inversa de la matriz $A$ y la representamos como $A^{-1}$.
Las matrices regulares siempre son cuadradas y su inversa también lo es.
Una propiedad que nos interesa enormemente para comprobar que una matriz es regular y calcular su inversa es que dicha matriz tiene rango $n$ para $n$ filas y, además, su forma normal de Hermite es la matriz identidad $n \times n$.
Sabiendo esto, podemos componer una matriz rectangular de tamaño $x \times 2n$ que contenga la matriz cuya inversa queremos calcular y, a su derecha, $Id_n$, de forma que las operaciones elementales que hagamos para normalizarla y llegar a la identidad en la mitad izquierda se traduzcan en la matriz inversa en la mitad derecha.
Vamos a verlo claramente con un ejemplo en $\mathbb{Z}_5$:

\[
	A =
	\begin{pmatrix}
		1 & 4 \\
		2 & 2
	\end{pmatrix}
\]

\[
	\begin{pmatrix}
		1 & 4 & 1 & 0 \\
		2 & 2 & 0 & 1
	\end{pmatrix}
	\xrightarrow{E_{12}(3)}
	\begin{pmatrix}
		1 & 4 & 1 & 0 \\
		0 & 4 & 3 & 1
	\end{pmatrix}
	\xrightarrow{E_{2}(4)}
	\begin{pmatrix}
		1 & 4 & 1 & 0 \\
		0 & 1 & 2 & 4
	\end{pmatrix}
	\xrightarrow{E_{21}(1)}
	\begin{pmatrix}
		1 & 0 & 3 & 4 \\
		0 & 1 & 2 & 4
	\end{pmatrix}
\]

\[
	A^{-1} =
	\begin{pmatrix}
	3 & 4 \\
	2 & 4
	\end{pmatrix}
\]

\[
	A \cdot A^{-1} = A^{-1} \cdot A =
	\begin{pmatrix}
		1 & 4 \\
		2 & 2
	\end{pmatrix}
	\cdot
	\begin{pmatrix}
	3 & 4 \\
	2 & 4
	\end{pmatrix}
	=
	\begin{pmatrix}
	3 & 4 \\
	2 & 4
	\end{pmatrix}
	\cdot
	\begin{pmatrix}
		1 & 4 \\
		2 & 2
	\end{pmatrix}
	=
	\begin{pmatrix}
		1 & 0 \\
		0 & 1
	\end{pmatrix}
\]
